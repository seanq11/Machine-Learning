{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1308ea1-b9a2-4f7a-b000-f41d0b38aff2",
   "metadata": {},
   "source": [
    "# Machine Learning (CMP3751M/CMP9772M) - Assessment 02\n",
    "\n",
    "Through the following notebook, you will be analysing a dataset and fitting a classification model to this dataset.\n",
    "\n",
    "The assessment is structured as follows:\n",
    "- [Dataset description](#Dataset-description)\n",
    "- [Loading the dataset](#Loading-the-dataset)\n",
    "- [Simple classification model](#Simple-classification-model)\n",
    "    - [Creating a training and testing set](#Creating-a-training-and-testing-set)\n",
    "    - [Training a classifier](#Training-a-classifier)\n",
    "- [Improved evaluation strategy](#Improved-evaluation-strategy)\n",
    "- [Different models and parameter search](#Different-models-and-parameter-search)\n",
    "- [Ensembles](#Ensembles)\n",
    "- [Final model evaluation](#Final-model-evaluation)\n",
    "- [References](#References)\n",
    "\n",
    "**Notes:**\n",
    "- The (%) noted above are out of 100; this will be scaled down to **maximum of 60 marks** for the assessment **(or maximum of 50 marks for CMP9772M)** .\n",
    "- Any discussion not supported by your implementation will not be awarded marks.\n",
    "- **Do not modify** and code provided as a **TESTING CELL**.\n",
    "- Make sure to **fix all the random seeds** in any parts of your solution, so it can be reproduced exactly.\n",
    "- The notebook, as provided, runs without errors (without solving the assessment). Make sure that the solution, or the partial solution, you hand in, also **runs without errors** on the data provided. If you have a partial solution causing errors which you would like to show, please include it as a comment.\n",
    "- Take care to include references to any external sources used. Check the [References](#References) section, the below cell, and the exambles through the assessment text for examples of how to do this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54719c9-3bc8-47c1-b620-831b73083ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to reference your sources! Check the bottom of the file, and examples used in the text of the assessment,\n",
    "# for including references to papers and software in your textual answers\n",
    "\n",
    "# Also add a reference in your solution cell before defining a class/function/method, eg.:\n",
    "\n",
    "# This code is a modified and extended version of [2]\n",
    "# OR\n",
    "# This code is a modified and extended version of https://stackoverflow.com/q/522563/884412\n",
    "##############\n",
    "## THE CODE ##\n",
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af12af-dd93-44ba-a161-dbab8f2017c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset description\n",
    "\n",
    "The the assessment will be done on the dataset containing only numerical features describing the physical and chemical properties of the Li-ion battery, which can be classified on the basis of their crystal system [1]. (The dataset for this assessment has been adapted from the full dataset which can be found [here](https://www.kaggle.com/datasets/divyansh22/crystal-system-properties-for-liion-batteries), shared in the public domain by Divyansh Agrawal).\n",
    "\n",
    "Each sample corresponds to the properties of a battery, and consists of following features:\n",
    "\n",
    "| Feature Name      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Formation Energy`       | `float`: eV | Formation energy of the material. |\n",
    "| `E Above Hull` | `float`: eV | Energy of decomposition of material into most stable ones. |\n",
    "| `Band Gap` | `float`: eV | Band gap. |\n",
    "| `Nsites` | `int`: count | Number of atoms in the unit cell of the crystal. |\n",
    "| `Density` | `float`: gm/cc | The density of bulk crystalline materials. |\n",
    "| `Volume` | `float` | The unit cell volume of the material. |\n",
    "\n",
    "The goal for the assessment is to predict whether the crystal system of the battery is _monoclinic_, _orthorhombic_ or _triclinic_, which provides a classification for each sample:\n",
    "\n",
    "| Class      | Value | Description |\n",
    "| :---------------- | :----- | ----------- |\n",
    "| `Crystal System`  | `string`: class designation | Class of the crystal system. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3ee2b-8c56-49f4-a5da-bbc7330283cb",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "The dataset is given in _batteries.csv_ file provided on Blackboard. **Load the dataset into two [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html)s.**: \n",
    "- The variable `X` should be a 2D [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) containing all the samples and their features from the dataset, one sample per row. \n",
    "- The variable `y` should be a 1D [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html) containing the ground truth (class) as given in the `'Crystal System'` field of the _.csv_ file.\n",
    "- _Note_: The class in the `'Crystal System'` column is given as a string. Make sure you encode the class as an integer number in your ground truth `y`.\n",
    "- _Note_: You should make sure that your code for loading the dataset is guided by the information about the dataset, and the dataset description you provide as your answer.\n",
    "\n",
    "**Describe the dataset**. Provide a basic description of the dataset. How many samples are there in the dataset? How many distinct classes? What types of features describe the samples in the dataset? Are there any missing values in the dataset? (Make sure these are properly handled). \n",
    "- _Note_: Make sure all your answers are supported by your implementation. Answers not supported by your implementation will not score any marks.\n",
    "\n",
    "Provide your code to _load the dataset_ and the code that will allow you to _describe the dataset_ in the **SOLUTION CELL**. Provide your description of the dataset in the **ANSWER CELL**. A correct solution should result in no errors when running the **TESTING CELL** provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc2b74-5ce4-47ba-815a-138e893c599c",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864efeba-7dec-4aad-b80b-0ab256868a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################`\n",
    "\n",
    "######## replace this code #####\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('batteries.csv')\n",
    "\n",
    "# Analyse the dataset\n",
    "num_samples = df.shape[0]\n",
    "num_features = df.shape[1] - 1  \n",
    "num_classes = df['Crystal System'].nunique()\n",
    "missing_values = df.isnull().sum().sum()\n",
    "\n",
    "# Handle missing values using median\n",
    "df['Formation Energy'] = df['Formation Energy'].fillna(df['Formation Energy'].median())\n",
    "df['Band Gap'] = df['Band Gap'].fillna(df['Band Gap'].median())\n",
    "df['Density'] = df['Density'].fillna(df['Density'].median())\n",
    "\n",
    "# Encode the 'Crystal System' column\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df['Crystal System'])\n",
    "\n",
    "# Extract the features\n",
    "X = df.drop('Crystal System', axis=1).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473348d6-2cda-4017-b3b0-290ea52db74e",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3ed4f9-8d94-41f8-8f12-b18919fbe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(X.shape) == 2)\n",
    "assert(len(y.shape) == 1)\n",
    "assert(X.shape[0] == y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60db068-206c-4471-8b54-780a653cc315",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4e42d-cc07-4982-91fb-97c7b2f282a1",
   "metadata": {},
   "source": [
    "The dataset has 399 samples, 6 features (Formation Energy, E Above Hull, Band Gap, Nsites, Density, Volume), 3 classes (Monoclinic, Orthorhombic, Triclinic) and there were 5 missing values. To handle the missing values, I decided on using a simple method of median imputation. The reason for this over a more complex imputation such a KNN imputation is because of how few missng values there were. There were only 5 missing values so using this method should not affect or skew the dataset and will have a much lower computational cost compared to a more complex method that wouldn't provide a significantly better result(Zhang, 2016). Each feature has some outliers however I haven't handled these by trimming them out as this may affect my results in the future and based on the fact we can assume there are no errors in the dataset I will leave them how they are for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b0117c-fdca-4d5a-9139-c0addbeb94a2",
   "metadata": {},
   "source": [
    "## Simple classification model\n",
    "\n",
    "To get the feel for the dataset, the first step will be to build train a simple classification model for this dataset. Do this in two steps detailed below:\n",
    "1. Set aside some data for training and for testing.\n",
    "2. Train a simple classifier on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac10b8-eac0-4b64-a82e-40781846c8d1",
   "metadata": {},
   "source": [
    "### Creating a training and testing set\n",
    "\n",
    "**Set aside 20\\% of the data for testing, and use the remaining 80\\% to train your model.** Make sure to fix any random seeds if you use any functions or methods relying on those, so your experiments are _fully repeatable_. Initialise the following variables:\n",
    "- `X_train` should contain the features corresponding to your training data.\n",
    "- `y_train` should contain the ground truth of your training data.\n",
    "- `X_test` should contain the features corresponding to your testing data.\n",
    "- `y_train` should contain the ground truth associated to your testing data.\n",
    "\n",
    "_Note:_ No additional marks will be rewarded for implementing an advanced data splitting strategy on this task. The purpose of this task is to start working with the dataset by applying a simple approach; you will have the chance to implement more complex evaluation pipelines in a later task.\n",
    "\n",
    "Provide your implementation in the **SOLUTION CELL (a)** below. A correct solution should result in no errors when running the **TESTING CELL** provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bc50e-8318-428d-b29b-220b4dadb283",
   "metadata": {},
   "source": [
    "### Training a classifier\n",
    "\n",
    "**Train a simple classifier,** (of your choosing) **with fixed parameters** on the dataset, and **calculate accuracy on the test set**.\n",
    "- Define a function `model_accuracy(y_test, y_pred)` to compare the ground truth given in `y_test` to predictions given in `y_pred` and calculate accuracy.\n",
    "- **Store the model** in the variable named `model`. For the model, you may chose any classifier with which you are familiar (e.g. K Nearest Neighbours), or implement your own classifier. Make sure you **train your model** using the _training data_ only (`X_train`, `y_train`).\n",
    "- Use the model to **predict the classes of the data** in the testing set (`X_test`), and calculate the accuracy by comparing the predictions with the ground truth for the testing set (`y_test`). **Store the predictions** in a variable called `y_test`.\n",
    "\n",
    "_Note:_ Do not implement an advanced strategy to chose the parameters of your classifier here, as that will be a topic of a latter question.\n",
    "\n",
    "_Note:_ If you implement your own classifier, make sure you implement it as a _class_ following the _sklearn_ standard for classifiers (i.e. make sure it implements the `fit(X, y)` method to train the model, and `predict(X)` method to use the trained model to predict the classes of provided samples.\n",
    "\n",
    "\n",
    "**Discuss the advantages and shortcomings** of the evaluation strategy implemented through this task. Discuss both the data split used for evaluation and the choice of metric. Taking into account the information you know about the dataset, what kind of accuracy scores can you expect on this dataset from a good and bad performing model? Based on the information you have so far, comment on the performance of the model you have trained on the provided dataset.\n",
    "\n",
    "Provide your implementation in the **SOLUTION CELL (b)** below. The **TESTING CELL** below should run without errors and will print the prediction of your model for the first sample in the test set, and the accuracy as calculated by your `model_accuracy` function. Provide your discussion in the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d0156-553b-4c89-a594-fa1c88e592b4",
   "metadata": {},
   "source": [
    "**SOLUTION CELL (a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c823edbd-0d8b-4238-9ae7-db683d651b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "\n",
    "######### replace these lines ##\n",
    "#X_train = np.array([[2,1]])\n",
    "#y_train = np.array([1])\n",
    "#X_test = np.array([[2,1]])\n",
    "#y_test = np.array([1])\n",
    "\n",
    "#Split dataset into train and test 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "################################\n",
    "# X_train = ...\n",
    "# y_train = ...\n",
    "# X_test = ...\n",
    "# y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046238d-602f-4ed1-8f41-cd71fdbb853d",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31fc35ed-610c-47bc-acce-0060f0f72034",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_train.shape[0] == y_train.shape[0])\n",
    "assert(X_test.shape[0] == y_test.shape[0])\n",
    "assert(X_train.shape[1] == X_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52af37dd-393c-4278-9972-c10677ad6189",
   "metadata": {},
   "source": [
    "**SOLUTION CELL (b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0e7c2a-5d95-4071-ae09-68c14e00bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def model_accuracy(y_test, y_pred):\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "##### replace these lines ######\n",
    "\n",
    "# Define the classifier\n",
    "model = KNeighborsClassifier()\n",
    "# Train the classifier\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4e3e6-be93-4fd5-9611-ec06c2a4610a",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1d52b9-7543-4d59-90d6-43ad5cf08229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "0.45588235294117646\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_test[0].reshape(1,-1)))\n",
    "print(model_accuracy(y_test, y_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae302f-0899-481e-8901-de9efe493da1",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bd068-84e1-4014-8696-02e3abfe8455",
   "metadata": {},
   "source": [
    "From this dataset, a good performing model should be able to predict the battery class with a higher accuracy, a number closer to 1, however, with a complex dataset, even a good model may not achieve a very high accuracy score. Where as, a bad performing model will have a lower accuracy score, this can be expected when using a more simple model especially on a complex dataset. Accuracy was the only metric for this evaluation which may not be the best way to capture the complexity of the dataset and evaluate the model as accuracy cannot \"distinguish between the number of correct labels of different classes\"(Sokolova, Japkowicz and Szpakowicz, 2006), other things such as precision, recall, and the use of a confusion matrix would improve the evaluation of the model used which would also help improve predictions. In this code I used a 80% - 20% split where 80% of the data was used for training and 20% was used for testing. The model I chose for this task was the K Nearest Neighbours (KNN) for its simple implementation and it is also easy to understand which makes it a good starting point for this dataset and should allow me to implement a more complex model in future tasks. The simplicity of the KNN model does mean that the complexities of the dataset are not taken into account which may be a reason for the poor performance. The accuracy score of the model was 0.4 which implies that the model isn't very good at predicting the class based on the dataset meaning the dataset may be too complex for the KNN model. Another thing to consider is that outliers are in the dataset which could cause the model issues when predicting a class. This is something that may need to be dealt with in future tasks. Other things I should consider going forward should be cross-validation to remove the variability of the dataset, a more sophisticated model should be implemented to achieve a higher accuracy score and to get better predicion results, and also using more evaluation metrics to understand and predict the data better.(Peterson, 2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa832abe-5688-43e2-8d1f-b655b7d4b142",
   "metadata": {},
   "source": [
    "## Improved evaluation strategy\n",
    "\n",
    "After discussing the shortcomings of the simple evaluation strategy used in the previous task, you now have a chance to **propose a better evaluation strategy.** Make sure your chosen strategy **uses all the samples in the dataset** to report the result.\n",
    "- Implement a function `evaluate_model(model, X, y)` to implement your proposed evaluation strategy. The function should evaluate the model given in `model` on the dataset given by `X` with ground truth given by `y`. Note that the function should be passed the _whole of the dataset_ (see **TESTING CELL** below) and should take care of any data splitting internally.\n",
    "- If desired, you may add additional arguments to this function, as long as they have default values and the function runs correctly when called using those default values.\n",
    "- The function should return no values, but instead print the results of the evaluation in a human-readable format.\n",
    "- Include at least one summative metric (providing a single number, e.g. accuracy) and per-class metric (e.g. precision). You are encouraged to select more than one metric of each type.\n",
    "\n",
    "This function will be used to provide a better evaluation of the simple model with fixed parameters used in the previous task.\n",
    "\n",
    "**Discuss your chosen evaluation strategy**, including both the data split and the evaluation metrics. Which data splitting strategy did you chose and why? Which metrics did you chose, and why? Briefly explain the chosen data splitting strategy. What additional information can your additional metrics provide beyond accuracy?\n",
    "\n",
    "Provide your implementation of this function in the **SOLUTION CELL**. You may also include any additional evaluation calls you want to include in this code cell. The **TESTING CELL** will perform a basic evaluation of your `model` using the `evaluate_model` function implemented for this task. Provide your discussion in the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e4c6a-7818-4b68-a7db-14e73dae16b8",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9c1591-9cfa-4831-9f56-d42557f31897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report,accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, X, y, n_splits=4):\n",
    "    print(f'Evaluating model {model} ...')\n",
    "    ################################\n",
    "    #### ADD YOUR SOLUTION HERE ####\n",
    "    ################################\n",
    "    # Using StratifiedKFold for cross-validation to maintain the proportion of each class\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Summative Metric is Accuracy\n",
    "    accuracies = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "    print(f\"Average Accuracy: {accuracies.mean():.2f} (+/- {accuracies.std() * 2:.2f})\")\n",
    "\n",
    "    # Per-Class Metrics are Precision, Recall, F1-Score\n",
    "    # Iterating over each fold and training the model,\n",
    "    # then predicting and generating a classification report.\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Train model on the current fold\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predictions based on current fold\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Print the report\n",
    "        print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa6d8f2-fae8-4f49-839c-3c145b4573c3",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a5b7ca-e08d-4bf0-8b0b-2aeb4ee4982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model KNeighborsClassifier() ...\n",
      "Average Accuracy: 0.55 (+/- 0.10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.45      0.57      0.51        35\n",
      "orthorhombic       0.53      0.50      0.52        32\n",
      "   triclinic       0.55      0.33      0.41        18\n",
      "\n",
      "    accuracy                           0.49        85\n",
      "   macro avg       0.51      0.47      0.48        85\n",
      "weighted avg       0.50      0.49      0.49        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.58      0.74      0.65        35\n",
      "orthorhombic       0.68      0.66      0.67        32\n",
      "   triclinic       0.67      0.33      0.44        18\n",
      "\n",
      "    accuracy                           0.62        85\n",
      "   macro avg       0.64      0.58      0.59        85\n",
      "weighted avg       0.63      0.62      0.61        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.60      0.58        35\n",
      "orthorhombic       0.59      0.69      0.64        32\n",
      "   triclinic       0.45      0.28      0.34        18\n",
      "\n",
      "    accuracy                           0.56        85\n",
      "   macro avg       0.54      0.52      0.52        85\n",
      "weighted avg       0.55      0.56      0.55        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.50      0.71      0.59        34\n",
      "orthorhombic       0.58      0.47      0.52        32\n",
      "   triclinic       0.50      0.28      0.36        18\n",
      "\n",
      "    accuracy                           0.52        84\n",
      "   macro avg       0.53      0.48      0.49        84\n",
      "weighted avg       0.53      0.52      0.51        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46babc-b9bb-4825-9a24-2f4ef812d493",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6281e9-3b43-41fd-9c67-fd2caf83a071",
   "metadata": {},
   "source": [
    "The data splitting strategy I chose for this task was k-fold cross-validation. For this, the data is split into 'k' folds and then the 'k' number is used to determine how many times the model is trained and tested. I chose a 'k' number of 4 as it seemed to provide the best results. Using this approach gets the most out of the data as it ensures all datapoints are used for the training and the testing. This approach is better than a single iteration of a test train split as it \"can stabilize the variability of accuracy estimates\"(Wong and Yeh, 2020). stratification was also used in this split as it keeps a balanced amount of each class in each fold and as this dataset has imbalanced class amounts, using stratified sampling helps to make sure each fold is representative of the dataset as a whole.\n",
    "\n",
    "The metrics I chose to use for this model evaluation were accuracy, precision, recall, and F1 score. Accuracy was the only summative metric I used and it helps to give an overall look at how good the model is at predicting the classes. The first of the per-class metrics I used was precision, This allows us to see how many false positives the model gives. A lower precision score indicates more false positives and vice versa. Recall shows the models ability to find all the positive instances. A higher recall number shows a lower false negative rate. F1 score uses both precision and recall, a higher F1 score shows that the model can balance not missing positives and not misclassifying negatives as positives(Sokolova, Japkowicz and Szpakowicz, 2006). As the dataset has an imbalanced amount of each class, using these metrics allow us to see how the model deals with each class seperately. This level of analysis is overlooked by just using an accuracy score. The support column in the summary shows how many instances of each class was used in each fold. This helps us get a better look at the amount of each class the model was trained and tested on during each individual fold and if they are imbalanced we should take it into account when interpretting the model evaluation. For example, if the support for a certain class is low, then the accuracy and recall may be less reliable because of the smaller sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce4cf3-0f68-4884-bf55-e76eed093144",
   "metadata": {},
   "source": [
    "## Different models and parameter search\n",
    "\n",
    "Now that you have a [better evaluation strategy](#Improved-evaluation-strategy) implemented, it is time to try out different models, and try out different parameter combinations for these models.\n",
    "\n",
    "**Fit at least three different (types of) machine learning models** to the provided dataset. (_Note:_ Make sure at least 2 out of your 3 chosen types have different model parameters which can be adjusted). **Try different parameters for all of your models** (which have parameters). Use a single summative metric of your choice to choose between the different types of models, and the models with different parameters. Finally, **choose thee different models, one of each type** and assign them to variables `model_1`, `model_2` and `model_3`.\n",
    "\n",
    "**Discuss your choice of models, and your procedure to adjust the model parameters**. Discuss how you reached the decision about the best model amongst the models of the same type (which metric was selected, and why). Also discuss any shortcomings of your approach and how (and if) you could improve on this. After evaluating these models on the dataset, **discuss and compare their performance on the provided data.**\n",
    "\n",
    "Implement your solution in the **SOLUTION CELL**. The **TESTING CELL** will evaluate the three best models selected by you, using your evaluation strategy. Discuss your choices in the **ANSWER CELL**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353db6d-39a5-4022-bee1-4b55d5bb4d09",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adfbbe1a-4a42-4681-859b-bc4bf348d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "##### replace these lines ######\n",
    "# set the parameter grid for KNeighborsClassifier\n",
    "parameters_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 10],  # Number of neighbors to use\n",
    "    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']  # Distance metric to use\n",
    "}\n",
    "knn = KNeighborsClassifier()# Initialise KNeighborsClassifier\n",
    "clf_knn = GridSearchCV(knn, parameters_knn, cv=5, scoring='accuracy', n_jobs=-1)# Set up parameter tuning with grid search\n",
    "clf_knn.fit(X_train, y_train)# Fit the classifier to the training data\n",
    "model_1 = clf_knn.best_estimator_ # Retrieve the best estimator found by GridSearchCV\n",
    "\n",
    "parameters_dt = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 4, 6]} # Set parameter range for max depth and min sample split\n",
    "dt = DecisionTreeClassifier() # Initialise decision tree\n",
    "clf_dt = GridSearchCV(dt, parameters_dt, cv=5, scoring='accuracy') # Grid search setup again\n",
    "clf_dt.fit(X_train, y_train) # Fit to data\n",
    "model_2 = clf_dt.best_estimator_ # Set model with best parameters\n",
    "\n",
    "parameters_svm = {'kernel': ('linear', 'rbf'), 'C': [1, 20]} # Set parameters for SVM\n",
    "svm = SVC() # Initialise SVM\n",
    "clf_svm = GridSearchCV(svm, parameters_svm, cv=5, scoring='accuracy') # Grid search setup\n",
    "clf_svm.fit(X_train, y_train) # Fit to data\n",
    "model_3 = clf_svm.best_estimator_ # Set model with best parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a52581-71a4-4c75-bc3a-861fe83e40a4",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2131851-eb53-4b64-8b12-d53af5612328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model KNeighborsClassifier(metric='manhattan') ...\n",
      "Average Accuracy: 0.56 (+/- 0.13)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.45      0.51      0.48        35\n",
      "orthorhombic       0.52      0.53      0.52        32\n",
      "   triclinic       0.50      0.33      0.40        18\n",
      "\n",
      "    accuracy                           0.48        85\n",
      "   macro avg       0.49      0.46      0.47        85\n",
      "weighted avg       0.49      0.48      0.48        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.58      0.71      0.64        35\n",
      "orthorhombic       0.68      0.72      0.70        32\n",
      "   triclinic       0.88      0.39      0.54        18\n",
      "\n",
      "    accuracy                           0.65        85\n",
      "   macro avg       0.71      0.61      0.63        85\n",
      "weighted avg       0.68      0.65      0.64        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.59      0.63      0.61        35\n",
      "orthorhombic       0.63      0.69      0.66        32\n",
      "   triclinic       0.46      0.33      0.39        18\n",
      "\n",
      "    accuracy                           0.59        85\n",
      "   macro avg       0.56      0.55      0.55        85\n",
      "weighted avg       0.58      0.59      0.58        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.48      0.74      0.58        34\n",
      "orthorhombic       0.58      0.44      0.50        32\n",
      "   triclinic       0.50      0.22      0.31        18\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.52      0.47      0.46        84\n",
      "weighted avg       0.52      0.51      0.49        84\n",
      "\n",
      "\n",
      "Evaluating model DecisionTreeClassifier(max_depth=10, min_samples_split=6) ...\n",
      "Average Accuracy: 0.57 (+/- 0.12)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.51      0.57      0.54        35\n",
      "orthorhombic       0.57      0.50      0.53        32\n",
      "   triclinic       0.39      0.39      0.39        18\n",
      "\n",
      "    accuracy                           0.51        85\n",
      "   macro avg       0.49      0.49      0.49        85\n",
      "weighted avg       0.51      0.51      0.51        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.74      0.66      0.70        35\n",
      "orthorhombic       0.72      0.88      0.79        32\n",
      "   triclinic       0.47      0.39      0.42        18\n",
      "\n",
      "    accuracy                           0.68        85\n",
      "   macro avg       0.64      0.64      0.64        85\n",
      "weighted avg       0.67      0.68      0.67        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.51      0.57      0.54        35\n",
      "orthorhombic       0.62      0.62      0.62        32\n",
      "   triclinic       0.50      0.39      0.44        18\n",
      "\n",
      "    accuracy                           0.55        85\n",
      "   macro avg       0.55      0.53      0.53        85\n",
      "weighted avg       0.55      0.55      0.55        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.55      0.71      0.62        34\n",
      "orthorhombic       0.61      0.44      0.51        32\n",
      "   triclinic       0.53      0.50      0.51        18\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.56      0.55      0.55        84\n",
      "weighted avg       0.57      0.56      0.55        84\n",
      "\n",
      "\n",
      "Evaluating model SVC(C=20) ...\n",
      "Average Accuracy: 0.48 (+/- 0.07)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.45      0.77      0.57        35\n",
      "orthorhombic       0.40      0.31      0.35        32\n",
      "   triclinic       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.44        85\n",
      "   macro avg       0.28      0.36      0.31        85\n",
      "weighted avg       0.34      0.44      0.37        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.47      0.83      0.60        35\n",
      "orthorhombic       0.65      0.47      0.55        32\n",
      "   triclinic       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.52        85\n",
      "   macro avg       0.37      0.43      0.38        85\n",
      "weighted avg       0.44      0.52      0.45        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.48      0.69      0.56        35\n",
      "orthorhombic       0.70      0.50      0.58        32\n",
      "   triclinic       0.33      0.22      0.27        18\n",
      "\n",
      "    accuracy                           0.52        85\n",
      "   macro avg       0.50      0.47      0.47        85\n",
      "weighted avg       0.53      0.52      0.51        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.43      0.85      0.57        34\n",
      "orthorhombic       0.58      0.22      0.32        32\n",
      "   triclinic       0.60      0.17      0.26        18\n",
      "\n",
      "    accuracy                           0.46        84\n",
      "   macro avg       0.54      0.41      0.38        84\n",
      "weighted avg       0.53      0.46      0.41        84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanquinton/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanquinton/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanquinton/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanquinton/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanquinton/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/seanquinton/anaconda3/envs/myenv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_1, X, y)\n",
    "print()\n",
    "evaluate_model(model_2, X, y)\n",
    "print()\n",
    "evaluate_model(model_3, X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ae54c-06a2-4f7e-8fee-80ba278be269",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6439d8-ec84-42d3-8a75-dda5217e871f",
   "metadata": {},
   "source": [
    "The first model I chose was K-Nearest neighbour. This model works by classifying based on its 'k' closest neighbours of features. This model has the benefit of being intuative to implement and simple. The model also allows for good parameter tuning which i utilised and will talk about in the next paragraph(Peterson, 2009). The next model I used was a decision tree classifier, the reason I chose this is because of its ability to see non-linear relationships(Swain and Hauska, 1977). The third model I used was a support vector machine (SVM). The main reason I chose this model is becuase of its ability to classify linear and non-linear relationships if the correct parameters are chosen(Mechelli and Vieira, 2019).\n",
    "\n",
    "For parameter adjustment and finding the optimal parameters for each model, I used a grid search function. This function trains the model on a range of parameters, testing for the best combination of parameters for the model and the dataset(Liashchynskyi and Liashchynskyi, 2019). Cross validation was used to evaluate the performance of the grid search as it ensures a lack of overfitting(Berrar, 2019). For the K-Nearest neighbour model, the parameters that were tuned were: 'n_neighbours', 'weights', and 'metric'. For the decision tree it was:'max_depth', and 'min_samples_split'. For the SVM the parameters were: 'C', 'kernel', and 'gamma'. The code \"best_parameter_\" is used to implement the best parameter for the model found by the grid search. The range of parameters in grid search may not be exhaustive meaning that it may miss an optimal configuration comapred to something like a randomised search which would be less computationally intensive over a broader range compared to grid search. However, the reason I did use grid search was because of it's compatibility with cross-validation as well as the fact it will improve each model with it's tuning abilities.\n",
    "\n",
    "The one metric I used as the primary metric for evaluating the models was accuracy, this is because it is a simple way to get an overview of how the model has performed as a whole. However, accuracy is not the best metric as it does have some flaws for example if the dataset is imbalanced the accuracy score may be misleading as things such as false positives and false negatives are not considered in the accuracy score. Using a metric such as f1 score, precision, and recall would help deal with an imbalanced dataset and take false positives and negatives into account(Sokolova, Japkowicz and Szpakowicz, 2006).\n",
    "\n",
    "The worst performing model was the support vector machine with an accuracy score of 0.48. The next best performing model was KNN whcih had an accuracy score of 0.56. The best perfoming model was decision trees with an accuracy score of 0.57. The underperformance of the SVM may be down to a few factors such as poor parameter selection, maybe my method for parameter tuning was not optimal and an appropriate kernel was not used and this could be a reason for the bad performance. Another reason could be the dataset was not optimal for an SVM as SVM does not work well with noisy data or where the data is not linearly seperable. This may be the case for our dataset. KNN was the second best performing model, one thing that may have affected the model's performance is a noisy dataset. If the dataset is noisy or has some outliers, then KNN will struggle a bit which could be a reason for the perfomance issues. The decision tree was the best performing but still didn't perform the greatest. A reason for this could be that although the decision trees can be more simple and easy to interpret, they can easily overfit. This can happen a lot when the tree become too deep. In comparison to SVM, decision trees can handle non-linear data well but they may not be able to interpret the complexities of the dataset.\n",
    "\n",
    "To improve on this task, I would look deeper in feature tuning to ensure the parameters are perfect for the dataset we have, This applies to all three models. I would also use more metrics such as F1 score, recall and precision to gain a better evaluation of how the models are performing on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d593d5af-582d-47ca-a341-c83bf318bfeb",
   "metadata": {},
   "source": [
    "## Ensembles\n",
    "\n",
    "Sometimes, combining different weak classification models can improve the overall performance of the model. **Implement bagging** for each of your three classification models (`model_1`, `model_2`, `model_3`) [from the previous task](#Different-models-and-parameter-search). Store your models performing bagging over your based models calculated in the previous task in variables called `bagged_1`, `bagged_2` and `bagged_3`. Provide your implementation, running any additional evaluation needed, in the **SOLUTION CELL**\n",
    "\n",
    "The **TESTING CELL** will evaluate your 3 bagged models using your own evaluation procedure. It will also make a voting ensemble consisting of your three base models (`model_1`, `model_2`, `model_3`) and another one made of your bagged models (`bagged_1`, `bagged_2` and `bagged_3`), and evaluate these three voting ensembles.\n",
    "\n",
    "**Discuss** the effect on bagging on your base models. Discuss how you chose the bagging parameters, and justify your choice. Discuss the effect using the voting ensemble had on your model performance. Compare the effect of a voting ensemble on the ensemble models to the effect on the base models. Provide your discussion in the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b14274-bfc0-45fc-87e5-96eb7d120a7e",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b8899c-d7fe-4518-bf82-d66442466bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged KNN - Accuracy: 0.41\n",
      "Bagged KNN - F1 Score: 0.39\n",
      "\n",
      "Bagged Decision Tree - Accuracy: 0.57\n",
      "Bagged Decision Tree - F1 Score: 0.56\n",
      "\n",
      "Bagged SVM - Accuracy: 0.44\n",
      "Bagged SVM - F1 Score: 0.38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "##### replace these lines ######\n",
    "\n",
    "# Bagging for KNN \n",
    "bagged_1 = BaggingClassifier(estimator=model_1, n_estimators=10, random_state=42)\n",
    "bagged_1.fit(X_train, y_train)\n",
    "\n",
    "# Bagging for decision tree\n",
    "bagged_2 = BaggingClassifier(estimator=model_2, n_estimators=10, random_state=42)\n",
    "bagged_2.fit(X_train, y_train)\n",
    "\n",
    "# Bagging for SVM\n",
    "bagged_3 = BaggingClassifier(estimator=model_3, n_estimators=10, random_state=42)\n",
    "bagged_3.fit(X_train, y_train)\n",
    "\n",
    "models_bagged = [bagged_1, bagged_2, bagged_3]\n",
    "model_names_bagged = ['Bagged KNN', 'Bagged Decision Tree', 'Bagged SVM']\n",
    "\n",
    "# Evaluate the performance of each bagged model\n",
    "for model, name in zip(models_bagged, model_names_bagged):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} - Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(f\"{name} - F1 Score: {f1_score(y_test, y_pred, average='weighted'):.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e6e22-4eb4-4c71-9c56-2043507671d4",
   "metadata": {},
   "source": [
    "**TESTING CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d08fc7e-899b-4511-8075-d816f652c68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model BaggingClassifier(estimator=KNeighborsClassifier(metric='manhattan'),\n",
      "                  random_state=42) ...\n",
      "Average Accuracy: 0.57 (+/- 0.06)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.53      0.54      0.54        35\n",
      "orthorhombic       0.50      0.53      0.52        32\n",
      "   triclinic       0.53      0.44      0.48        18\n",
      "\n",
      "    accuracy                           0.52        85\n",
      "   macro avg       0.52      0.51      0.51        85\n",
      "weighted avg       0.52      0.52      0.52        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.60      0.58        35\n",
      "orthorhombic       0.62      0.66      0.64        32\n",
      "   triclinic       0.57      0.44      0.50        18\n",
      "\n",
      "    accuracy                           0.59        85\n",
      "   macro avg       0.59      0.57      0.57        85\n",
      "weighted avg       0.59      0.59      0.59        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.58      0.63      0.60        35\n",
      "orthorhombic       0.61      0.62      0.62        32\n",
      "   triclinic       0.64      0.50      0.56        18\n",
      "\n",
      "    accuracy                           0.60        85\n",
      "   macro avg       0.61      0.58      0.59        85\n",
      "weighted avg       0.60      0.60      0.60        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.54      0.65      0.59        34\n",
      "orthorhombic       0.59      0.53      0.56        32\n",
      "   triclinic       0.57      0.44      0.50        18\n",
      "\n",
      "    accuracy                           0.56        84\n",
      "   macro avg       0.56      0.54      0.55        84\n",
      "weighted avg       0.56      0.56      0.56        84\n",
      "\n",
      "\n",
      "Evaluating model BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
      "                                                   min_samples_split=6),\n",
      "                  random_state=42) ...\n",
      "Average Accuracy: 0.60 (+/- 0.12)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.69      0.62        35\n",
      "orthorhombic       0.66      0.59      0.62        32\n",
      "   triclinic       0.64      0.50      0.56        18\n",
      "\n",
      "    accuracy                           0.61        85\n",
      "   macro avg       0.62      0.59      0.60        85\n",
      "weighted avg       0.62      0.61      0.61        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.66      0.71      0.68        35\n",
      "orthorhombic       0.66      0.72      0.69        32\n",
      "   triclinic       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.66        85\n",
      "   macro avg       0.66      0.63      0.63        85\n",
      "weighted avg       0.66      0.66      0.65        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.69      0.62        35\n",
      "orthorhombic       0.68      0.66      0.67        32\n",
      "   triclinic       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.62        85\n",
      "   macro avg       0.64      0.60      0.61        85\n",
      "weighted avg       0.63      0.62      0.62        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.47      0.59      0.52        34\n",
      "orthorhombic       0.56      0.47      0.51        32\n",
      "   triclinic       0.50      0.39      0.44        18\n",
      "\n",
      "    accuracy                           0.50        84\n",
      "   macro avg       0.51      0.48      0.49        84\n",
      "weighted avg       0.51      0.50      0.50        84\n",
      "\n",
      "\n",
      "Evaluating model BaggingClassifier(estimator=SVC(C=20), random_state=42) ...\n",
      "Average Accuracy: 0.50 (+/- 0.07)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.45      0.77      0.57        35\n",
      "orthorhombic       0.45      0.28      0.35        32\n",
      "   triclinic       0.80      0.22      0.35        18\n",
      "\n",
      "    accuracy                           0.47        85\n",
      "   macro avg       0.57      0.42      0.42        85\n",
      "weighted avg       0.52      0.47      0.44        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.48      0.86      0.62        35\n",
      "orthorhombic       0.67      0.44      0.53        32\n",
      "   triclinic       1.00      0.11      0.20        18\n",
      "\n",
      "    accuracy                           0.54        85\n",
      "   macro avg       0.72      0.47      0.45        85\n",
      "weighted avg       0.66      0.54      0.50        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.47      0.69      0.56        35\n",
      "orthorhombic       0.71      0.53      0.61        32\n",
      "   triclinic       0.30      0.17      0.21        18\n",
      "\n",
      "    accuracy                           0.52        85\n",
      "   macro avg       0.49      0.46      0.46        85\n",
      "weighted avg       0.52      0.52      0.50        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.43      0.88      0.58        34\n",
      "orthorhombic       0.58      0.22      0.32        32\n",
      "   triclinic       0.50      0.06      0.10        18\n",
      "\n",
      "    accuracy                           0.45        84\n",
      "   macro avg       0.50      0.39      0.33        84\n",
      "weighted avg       0.50      0.45      0.38        84\n",
      "\n",
      "\n",
      "Evaluating model VotingClassifier(estimators=[('CLF1', KNeighborsClassifier(metric='manhattan')),\n",
      "                             ('CLF2',\n",
      "                              DecisionTreeClassifier(max_depth=10,\n",
      "                                                     min_samples_split=6)),\n",
      "                             ('CLF3', SVC(C=20))]) ...\n",
      "Average Accuracy: 0.56 (+/- 0.15)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.45      0.74      0.56        35\n",
      "orthorhombic       0.52      0.41      0.46        32\n",
      "   triclinic       0.50      0.06      0.10        18\n",
      "\n",
      "    accuracy                           0.47        85\n",
      "   macro avg       0.49      0.40      0.37        85\n",
      "weighted avg       0.49      0.47      0.42        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.60      0.80      0.68        35\n",
      "orthorhombic       0.74      0.78      0.76        32\n",
      "   triclinic       1.00      0.22      0.36        18\n",
      "\n",
      "    accuracy                           0.67        85\n",
      "   macro avg       0.78      0.60      0.60        85\n",
      "weighted avg       0.73      0.67      0.64        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.53      0.69      0.60        35\n",
      "orthorhombic       0.70      0.66      0.68        32\n",
      "   triclinic       0.50      0.28      0.36        18\n",
      "\n",
      "    accuracy                           0.59        85\n",
      "   macro avg       0.58      0.54      0.54        85\n",
      "weighted avg       0.59      0.59      0.58        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.47      0.82      0.60        34\n",
      "orthorhombic       0.61      0.34      0.44        32\n",
      "   triclinic       0.57      0.22      0.32        18\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.55      0.46      0.45        84\n",
      "weighted avg       0.55      0.51      0.48        84\n",
      "\n",
      "\n",
      "Evaluating model VotingClassifier(estimators=[('BCLF1',\n",
      "                              BaggingClassifier(estimator=KNeighborsClassifier(metric='manhattan'),\n",
      "                                                random_state=42)),\n",
      "                             ('BCLF2',\n",
      "                              BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
      "                                                                                 min_samples_split=6),\n",
      "                                                random_state=42)),\n",
      "                             ('BCLF3',\n",
      "                              BaggingClassifier(estimator=SVC(C=20),\n",
      "                                                random_state=42))]) ...\n",
      "Average Accuracy: 0.58 (+/- 0.12)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.49      0.69      0.57        35\n",
      "orthorhombic       0.52      0.44      0.47        32\n",
      "   triclinic       0.78      0.39      0.52        18\n",
      "\n",
      "    accuracy                           0.53        85\n",
      "   macro avg       0.60      0.50      0.52        85\n",
      "weighted avg       0.56      0.53      0.52        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.58      0.80      0.67        35\n",
      "orthorhombic       0.67      0.62      0.65        32\n",
      "   triclinic       1.00      0.39      0.56        18\n",
      "\n",
      "    accuracy                           0.65        85\n",
      "   macro avg       0.75      0.60      0.63        85\n",
      "weighted avg       0.70      0.65      0.64        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.74      0.64        35\n",
      "orthorhombic       0.74      0.62      0.68        32\n",
      "   triclinic       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.64        85\n",
      "   macro avg       0.66      0.60      0.62        85\n",
      "weighted avg       0.65      0.64      0.63        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.47      0.79      0.59        34\n",
      "orthorhombic       0.61      0.34      0.44        32\n",
      "   triclinic       0.56      0.28      0.37        18\n",
      "\n",
      "    accuracy                           0.51        84\n",
      "   macro avg       0.55      0.47      0.47        84\n",
      "weighted avg       0.54      0.51      0.49        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf  = VotingClassifier(estimators=[('CLF1', model_1), ('CLF2', model_2), ('CLF3', model_3)], voting='hard')\n",
    "ebclf  = VotingClassifier(estimators=[('BCLF1', bagged_1), ('BCLF2', bagged_2), ('BCLF3', bagged_3)], voting='hard')\n",
    "\n",
    "\n",
    "evaluate_model(bagged_1, X, y)\n",
    "print()\n",
    "evaluate_model(bagged_2, X, y)\n",
    "print()\n",
    "evaluate_model(bagged_3, X, y)\n",
    "print()\n",
    "evaluate_model(eclf, X, y)\n",
    "print()\n",
    "evaluate_model(ebclf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17597da9-0556-4dec-992e-c14e0b9b618a",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e3a0e-f242-404d-a980-e8e9cc928b70",
   "metadata": {},
   "source": [
    "From this task, we can see that bagging effects each base model differently. For example, The KNN model wasn't improved by bagging as bagging usually improves models with high variance and low bias however, KNN has low variance and high bias. This means that the bagging is not suited for this model and this can be seen by the fact that bagging did not majorly improve the accuracy score. For the decision tree classifier, we can see improvement of 0.03 in the accuracy score. One reason for this may be because of the tendancy of overfitting that decision trees has and bagging can reduce noise and reduce variance leading to a better performing model. Bagging for decision trees is also the \"most commonly used procedure for bagging\"(Büchlmann and Yu, 2002) . For SVM, we saw in improvement from implementing bagging this may be because bagging introduces some diversity that allowed the model to perform better. SVM doesn't get affected by overfitting so this isn't an issue that would need to be solved by bagging.\n",
    "\n",
    "The two parameters used in the bagging classifier were 'n_estimators' and 'random_state'. The reason for these two parameters is because i thought it would improve the accuracy score the most for the lowest cost. For the random state i chose to use 42, this is because 42 seems to be standard practise for a random state parameter and the actual number chosen doesnt affect too much as long as it is consistent. For the n estimators i chose 10. I found that 10 provided the best result for all the models chosen and any numbers below reduced the accuracy and numbers above didnt drastically improve the accuracy.\n",
    "\n",
    "The voting ensemble provided an accuracy score of 0.56 for the base models and 0.58 for the bagged models. This shows that it didnt really improve the accuracy score or even the f1 score of the models especially decision trees which performed better than both voting ensembles. It did perform better than our SVM model which is an improvement. The voting ensemble for the bagged models also had a similar accuracy score and f1 score to the initial bagged results showing little to no improvement for the most part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4b762-a3ca-46ca-b7fa-6f5d5a58902b",
   "metadata": {},
   "source": [
    "## Final model evaluation\n",
    "\n",
    "Based on all the experiments performed for this assessment, **choose a single best model, evaluate it** with [your evaluation procedure](#Improved-evaluation-strategy) and also **display the confusion matrix**. **Discuss the performance achieved by this model**.\n",
    "\n",
    "**You should attempt this cell even if you have not successfully trained all the models required in this assessment, and comment on the best model which _you_ have obtanied.**\n",
    "\n",
    "Implement your solution in the **SOLUTION CELL** below. Add your discussion to the **ANSWER CELL** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ead24-194d-4953-adea-a0fe59caa586",
   "metadata": {},
   "source": [
    "**SOLUTION CELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6739096d-09a1-4d58-82ef-7c2822727451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=10,\n",
      "                                                   min_samples_split=6),\n",
      "                  random_state=42) ...\n",
      "Average Accuracy: 0.60 (+/- 0.12)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.69      0.62        35\n",
      "orthorhombic       0.66      0.59      0.62        32\n",
      "   triclinic       0.64      0.50      0.56        18\n",
      "\n",
      "    accuracy                           0.61        85\n",
      "   macro avg       0.62      0.59      0.60        85\n",
      "weighted avg       0.62      0.61      0.61        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.66      0.71      0.68        35\n",
      "orthorhombic       0.66      0.72      0.69        32\n",
      "   triclinic       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.66        85\n",
      "   macro avg       0.66      0.63      0.63        85\n",
      "weighted avg       0.66      0.66      0.65        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.57      0.69      0.62        35\n",
      "orthorhombic       0.68      0.66      0.67        32\n",
      "   triclinic       0.67      0.44      0.53        18\n",
      "\n",
      "    accuracy                           0.62        85\n",
      "   macro avg       0.64      0.60      0.61        85\n",
      "weighted avg       0.63      0.62      0.62        85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  monoclinic       0.47      0.59      0.52        34\n",
      "orthorhombic       0.56      0.47      0.51        32\n",
      "   triclinic       0.50      0.39      0.44        18\n",
      "\n",
      "    accuracy                           0.50        84\n",
      "   macro avg       0.51      0.48      0.49        84\n",
      "weighted avg       0.51      0.50      0.50        84\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "################################\n",
    "#### ADD YOUR SOLUTION HERE ####\n",
    "################################\n",
    "##### replace these lines ######\n",
    "\n",
    "# Use the bagged decsion tree made in a previous task \n",
    "bagged_2 = BaggingClassifier(estimator=model_2, n_estimators=10, random_state=42)\n",
    "bagged_2.fit(X_train, y_train)\n",
    "\n",
    "# Run the evaluation model made in a previous task\n",
    "evaluate_model(bagged_2, X, y)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred) # Initialise confusion matrix\n",
    "plt.figure(figsize=(8, 6)) # Set size of matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') # Make it a heat map and ive chosen to use different blues as the colurs \n",
    "class_names = ['monoclinic', 'orthorhombic', 'triclinic']  # add the original class names that we changed to 0,1,2 in a previos task, this is for better readability.\n",
    "plt.xticks(ticks=[0.5, 1.5, 2.5], labels=class_names)  # Set the x-tick labels with class names\n",
    "plt.yticks(ticks=[0.5, 1.5, 2.5], labels=class_names)  # Set the y-tick labels with class names\n",
    "plt.title('Confusion Matrix for bagged decision tree model') # Set title\n",
    "plt.ylabel('Actual Labels') # set name of x label and y label is below\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.show() # show the confucion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d736e-8e98-4bf4-8abe-537fbd297998",
   "metadata": {},
   "source": [
    "**ANSWER CELL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3562ce-0610-4055-8be5-b4c23103f245",
   "metadata": {},
   "source": [
    "The final ML model i chose for the dataset was the bagged verison of teh decsion trees model. The reason for this is because it had the highest accuracy score (0.60) as well as taking the other metrics into account (f1 score, precision, recall) it seemed to perform the best in more cases than any other model or bagged model or voting ensemble. However, from looking at the metrics used as well as the confusion matrix, we can see that the model is far from perfect and still gives false negatives and false positives. For example, if we look at the confusion matrix, we can see that monoclinic was a true positive in the most cases (23) however 16 times it was classed as triclinic and 13 times as orthorhombic. This is not very accurate at all. This could be down to things such as the model itself, my parameter selection and tuning or noisey data in the dataset that makes it harder for the model to predict. Orthorhombic was correctly classified 6 times but it was wrongly classified as monoclinic more times (7) than it correctly predicted as orthorhombic showing a lack of accuracy in this area. it predicted it as triclinic 1 time which is better but cant stop us from ignoring the bad results. Triclinic was correctly identified 1 time and wronly identified as monoclinic 1 time meaning it only correctly predicts the category 50% of the time. Things we need to take into account for these results include the fact that there is significantly more monoclinic batteries in the data set than orthorhombic and triclinic which had the least. The variety of the dataset is something else we must consider as this will have made it much harder for the model to predict.\n",
    "\n",
    "In conclusion, the bagged decision tree model perfomed the best out of the models I chose however there is improvements to be made in order to refine and improve the success in correctly identifying the class of the batteries in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d346a-6c57-496b-8e0d-d2bf6d51485b",
   "metadata": {},
   "source": [
    "## Code References \n",
    "\n",
    "[1] Divyansh Agrawal: Crystal System Properties for Li-ion batteries (dataset) https://www.kaggle.com/datasets/divyansh22/crystal-system-properties-for-liion-batteries/discussion (accessed 28/08/2023)\n",
    "\n",
    "[2] Mateen Ulhaq, Mike Hordecki (code) https://stackoverflow.com/a/522578/884412 (accessed 24/08/2023)\n",
    "\n",
    "[3] Kumar, A.(code) Replace Missing Values with Mean, Median & Mode. https://vitalflux.com/pandas-impute-missing-values-mean-median-mode/#:~:text=Mean%20imputation%20is%20often%20used. (accessed 16/12/2023)\n",
    "\n",
    "[4] No author (code) Encoding a string:  https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html  (accessed 18/12/2023)\n",
    "\n",
    "[5] No author (code) train test split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html (accessed 18/12/2023)\n",
    "\n",
    "[6] Tom (code) https://stackoverflow.com/a/65895462 (accessed 19/12/2023)\n",
    "\n",
    "[7] haneulkim (code) https://stackoverflow.com/q/66600369 (accessed 19/12/2023)\n",
    "\n",
    "[8] No author (code) https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html (accessed 21/12/2023)\n",
    "\n",
    "[9] No author (code) https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html (accessed 21/12/2023)\n",
    "\n",
    "[10] No author (code) https://scikit-learn.org/stable/modules/cross_validation.html (accessed 21/12/2023)\n",
    "\n",
    "[11] No author (code) https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html (accessed 21/12/2023)\n",
    "\n",
    "[13] No author (code) https://scikit-learn.org/stable/modules/tree.html (accessed 29/12/2023)\n",
    "\n",
    "[14] No author (code) https://scikit-learn.org/stable/modules/svm.html (accessed 29/12/2023)\n",
    "\n",
    "[15] Muhammad Bilal Shahid, Venkatachalam (code) https://stackoverflow.com/questions/62115384/how-to-use-custom-metrics-in-keras-model-while-using-grid-search-cv (accessed 29/12/2023)\n",
    "\n",
    "[16] Michael Recachinas, Klausos Klausos, Sean Easter (code) https://stackoverflow.com/q/34189107 (accessed 30/12/2023)\n",
    "\n",
    "[17] No author (code) https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html (accessed 31/12/2023)\n",
    "\n",
    "[18] No author (code) https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions (accessed 08/01/2024)\n",
    "\n",
    "[19] No author (code) https://seaborn.pydata.org/generated/seaborn.heatmap.html (accessed 08/01/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d75ab21-faf8-47b9-8b4d-5a86b07cce9b",
   "metadata": {},
   "source": [
    "## Differences in referenced code\n",
    "\n",
    "\n",
    "[3] used the median code and added relevant features with missing values\n",
    "\n",
    "[4] used the import and the .fit_transform parameter\n",
    "\n",
    "[5] used train_test_split function and changed test_size to fit requirements\n",
    "\n",
    "[6] used the KNeighborsClassifier function as well as the .fit function\n",
    "\n",
    "[7] used the accuracy_score function\n",
    "\n",
    "[8] used stratifiedKFold line adn changed number of splits, random state, and shuffle\n",
    "\n",
    "[9] used cross_val_score function with my own variables as parameters.\n",
    "\n",
    "[10] used the for loop with the skf.split function and used my own data in the loop\n",
    "\n",
    "[11] used classification_report function and changed target names to the class labels.\n",
    "\n",
    "[13] used the basic code to implement the classifier, used my own code for parameters.\n",
    "\n",
    "[14] found how to use the SVC() function and used it within my own adapted code.\n",
    "\n",
    "[15] used the basic GridSearchCV function and found how to implement it from muhammad's code. I also used the scoring parameter from 'Venkatachalam' who responded to muhammad\n",
    "\n",
    "[16] found how to use 'best_estimator_' as well as what situation it can be used it to apply it to my own code. used the main question and some tips from the answer.\n",
    "\n",
    "[17] used the baggingclassifier() function and some of the parameters.\n",
    "\n",
    "[18] used the code to initialise the confusion matrix with confusion_matrix() and used y_test, y_pred as the parameters.\n",
    "\n",
    "[19] used the sns.heatmap code and used the parameters: annot,fmt,cmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32cad170-a881-49d0-972b-9639a24c29cc",
   "metadata": {},
   "source": [
    "## References\n",
    "Berrar, D. (2019). Cross-Validation. Encyclopedia of Bioinformatics and Computational Biology, 1, pp.542–545. doi:https://doi.org/10.1016/b978-0-12-809633-8.20349-x.\n",
    "\n",
    "Büchlmann, P. and Yu, B. (2002). Analyzing Bagging. The Annals of Statistics, [online] 30(4), pp.927–961. Available at: https://www.jstor.org/stable/1558692 [Accessed 14 Jan. 2024].\n",
    "\n",
    "Liashchynskyi, P. and Liashchynskyi, P. (2019). Grid Search, Random Search, Genetic Algorithm: A Big Comparison for NAS. arXiv:1912.06059 [cs, stat]. [online] Available at: https://arxiv.org/abs/1912.06059.\n",
    "\n",
    "Mechelli, A. and Vieira, S. (2019). Machine Learning: Methods and Applications to Brain Disorders. [online] Google Books. Academic Press. Available at: https://books.google.co.uk/books?hl=en&lr=&id=72C-DwAAQBAJ&oi=fnd&pg=PA101&ots=3VBXDdotB7&sig=jvtbUZmX3J8T-yOfgLKaV_AZRww&redir_esc=y#v=onepage&q&f=false [Accessed 14 Jan. 2024].\n",
    "\n",
    "Peterson, L. (2009). K-nearest neighbor. Scholarpedia, [online] 4(2), p.1883. doi:https://doi.org/10.4249/scholarpedia.1883.\n",
    "\n",
    "Sokolova, M., Japkowicz, N. and Szpakowicz, S. (2006). Beyond Accuracy, F-Score and ROC: A Family of Discriminant Measures for Performance Evaluation. Lecture Notes in Computer Science, pp.1015–1021. doi:https://doi.org/10.1007/11941439_114.\n",
    "\n",
    "Swain, P.H. and Hauska, H. (1977). The decision tree classifier: Design and potential. IEEE Transactions on Geoscience Electronics, 15(3), pp.142–147. doi:https://doi.org/10.1109/tge.1977.6498972.\n",
    "\n",
    "Wong, T. and Yeh, P. (2020). Reliable Accuracy Estimates from k-Fold Cross Validation. IEEE Transactions on Knowledge and Data Engineering, [online] 32(8), pp.1586–1594. doi:https://doi.org/10.1109/TKDE.2019.2912815.\n",
    "\n",
    "Zhang, Z. (2016). Missing data imputation: focusing on single imputation. Annals of translational medicine, [online] 4(1), p.9. doi:https://doi.org/10.3978/j.issn.2305-5839.2015.12.38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e599b-35cc-490c-af9c-22ffd71a28b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
